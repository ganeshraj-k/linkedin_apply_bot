{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.llms.openai import OpenAI\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.legacy.llms.ollama import Ollama\n",
    "\n",
    "llama_llm = Ollama(model=\"llama2\")\n",
    "gpt35_llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "gpt4_llm = OpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('./mydata').load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='4755adce-4bcd-4e30-acab-9e3c88e3e4f7', embedding=None, metadata={'file_path': 'c:\\\\Users\\\\localadmin\\\\Desktop\\\\myprojects\\\\linkedinsucks\\\\linkedinsucks_2\\\\RAG_models\\\\mydata\\\\QnA.json', 'file_name': 'QnA.json', 'file_type': 'application/json', 'file_size': 751, 'creation_date': '2024-08-07', 'last_modified_date': '2024-08-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='{\"Email address\": \"ganesh_012@outlook.com\", \"Phone country code\": \"United States (+1)\", \"Mobile phone number\": \"8483138525\", \"How many years of work experience do you have with PySpark?\": \"2\", \"How many years of work experience do you have with Data Engineering?\": \"3\", \"How many years of work experience do you have with Amazon Web Services (AWS)?\": \"3\", \"Have you completed the following level of education: Bachelor\\'s Degree?\\\\nHave you completed the following level of education: Bachelor\\'s Degree?\": \"Yes\", \"How many years of work experience do you have with Python (Programming Language)?\": \"4\", \"How many years of work experience do you have with Test Automation?\": \"1\", \"How many years of work experience do you have with Mobile Devices?\": \"1\"}', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='42ce7d71-29d6-45cf-863b-203e653e92cc', embedding=None, metadata={'page_label': '1', 'file_name': 'resume_july_2024_master.pdf', 'file_path': 'c:\\\\Users\\\\localadmin\\\\Desktop\\\\myprojects\\\\linkedinsucks\\\\linkedinsucks_2\\\\RAG_models\\\\mydata\\\\resume_july_2024_master.pdf', 'file_type': 'application/pdf', 'file_size': 191973, 'creation_date': '2024-08-08', 'last_modified_date': '2024-08-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Ganesh Raj K  \\n◆ ganesh_012@outlook.com    ◆   848 313 8525   ◆   linkedin.com/in/ganeshrajk    ◆   github.com/ganeshraj -k \\nEXPERIENCE : \\nRutgers UCM, Data Analyst         Feb 2023 – Present, New Brunswick  \\n• Harnessed learning data from canvas Api to predict new student course outcomes /CGPA grade  using a classification \\nmodel with 78 percent success rate  in classifying new students.  \\n• The dataset consisted of 12 diverse features including demographic academic, behavioral, parent participation for the \\npredictive modeling.  \\n• Extracted data using canvas Api, preprocessed using python, and used ANN for the classificatio n model.  \\nDeloitte Consulting, Data Analyst       June 2019 – Jan 2022, Bengaluru  \\nMedical Data NER:  \\n• Enhanced query speed for a medical record database with over 2 million records.  \\n• Used Amazon Comprehend with Python to perform Named Entity Recognition on the DynamoDB dataset.  \\n• Added recognized entities as tags using AWS Glue for the ETL process.  \\nRestaurant Chain:  \\n• Categorized restaurant patrons based on their dining preferences from survey data using K -Means clustering.  \\n• Generated detailed Tableau visualizations to correlate the cluster results with their risk and safety behaviors.  \\n• This analysis helped strategize marketing along with promotion of safety protocols. which led to an 74% increase in \\ntake away orders the next quarter.  \\nBanking:  \\n• Mitigated the lockdown -induced customer churn by constructing a multivariate logistic regression model to Identified \\nchurn -prone customers and key contributing factors.  \\n• Performed EDA using matplotlib and communicated results to stakeholders. helped them target marketing accordingly \\nresulting in a 30% churn reduction in the next quarter.       \\nGeospatial Intelligence:  \\n• Addressed the challenge of manually identifying docked vessels by developing an object detection system using Mask \\nR-CNN and OpenCV for change detection in Python.  \\n• Accessed high -definition GIS satellite imagery from the Sentinel API in Python and dehazed the images for better \\nresults.  \\n• Extracted the geolocation data of the detected objects using QGIS.  \\n• Automated the entire process using AWS Lambda and CloudWatch, saving over $100k in labor costs.  \\nKey Achievement : Was recognized with Applause award twice for my client centric work approach and timely \\ndeliverables.  \\n \\nMAQ Software, Data Engineer        May 2018 – July 2018, Hyderabad  \\n• Established an ETL pipeline using SQL Server Management Studio and SSIS, consolidating three large Azure d ata \\nmarts with over 2 million records into one. Developed triggers and stored procedures in place to identify \\ninconsistencies during the transfer and maintain data integrity.  \\n \\nPROJECTS:  \\n Chat bot with a personality : [github]  \\n• Built a generative AI (Gen AI) model chatbot to replicate Chandler Bing’s dialogue style from “Friends,” utilizing an \\nextensive dataset of 8,700 dialogues.  \\n•  The model, featuring a seq2seq with 2 -layer LSTM network with a dropout layer, achieved a BLEU score of 0.63.  \\n \\nTwitter Search:  [github]  \\n• Designed a web application with a local cache of 200 trending tweets, leveraging a combination of Postgres \\n(relational) and MongoDB (non -relational) to query a dataset of about 120,000 tweets from 13,000 users.  \\n• Applied NLP techniques for efficient search, including synonym search and Levenshtein distance, and managed API \\nrequests with  Flask  \\n \\n2024 Travelers Insurance Analytics University Contest:  \\n• Conducted Tweedie regression on a zero -inflated dataset of over 29,000 records, fine -tuned parameters using grid \\nsearch, and assessed model efficacy with the Gini index. This systematic approach secured a third -place finish \\namong 200+ teams.  \\n ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='15a8dbbf-4e6f-4f65-826d-4c2e75864264', embedding=None, metadata={'page_label': '2', 'file_name': 'resume_july_2024_master.pdf', 'file_path': 'c:\\\\Users\\\\localadmin\\\\Desktop\\\\myprojects\\\\linkedinsucks\\\\linkedinsucks_2\\\\RAG_models\\\\mydata\\\\resume_july_2024_master.pdf', 'file_type': 'application/pdf', 'file_size': 191973, 'creation_date': '2024-08-08', 'last_modified_date': '2024-08-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='EDUCATION:  \\n• MS in Data Science , Rutgers University         May 2024  \\n• BTech in Computer Science and Engineering , Indian Institute of Technology Indore   May 2019  \\n \\nSKILLS  \\n• Programming Languages:  Python, R  \\n• Machine Learning Libraries and Frame works:   PyTorch , scikit -learn, pandas, numpy  \\n• Cloud:  AWS, DynamoDB, Glue, EC2, SageMaker, IAM, S3  \\n• Office: Excel, PowerPoint, VBA  \\n• Data Visualization : Tableau, Matplotlib, Seaborn, Plotly  \\n \\nCERTIFICATIONS  \\n• AWS Machine Learning Specialist  \\n• AWS Cloud Practitioner  ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TEXT_QA_PROMPT_TMPL = (\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the query in the format requested in the query. \"\n",
    "    \"If there are options in the query, answer by choosing one or more options as required. \"\n",
    "    \"Keep the answers concise and to the point, do not answer long sentences unless necessary or specified.\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(llm = gpt4_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt_tmpl = PromptTemplate(\n",
    "    DEFAULT_TEXT_QA_PROMPT_TMPL\n",
    ")\n",
    "query_engine.update_prompts(\n",
    "    { \"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for the Position of Data Scientist at Barclays\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am writing to express my interest in the Data Scientist position at Barclays, as advertised. I am a Data Science professional with a Master's degree in Data Science from Rutgers University and a BTech in Computer Science and Engineering from the Indian Institute of Technology Indore. I believe my academic background and professional experience make me a strong candidate for this role.\n",
      "\n",
      "In my current role as a Data Analyst at Rutgers UCM, I have successfully harnessed learning data to predict student course outcomes with a 78% success rate. I have also worked with Deloitte Consulting as a Data Analyst, where I enhanced query speed for a medical record database with over 2 million records and developed an object detection system that saved over $100k in labor costs. These experiences have honed my skills in machine learning, data visualization, and cloud computing.\n",
      "\n",
      "I am proficient in Python and R programming languages and have extensive experience with machine learning libraries and frameworks such as PyTorch, scikit-learn, pandas, and numpy. I am also certified as an AWS Machine Learning Specialist and AWS Cloud Practitioner, which I believe will be beneficial in this role.\n",
      "\n",
      "In addition to my technical skills, I have a proven track record of delivering timely results and maintaining a client-centric work approach, as evidenced by my recognition with the Applause award twice during my tenure at Deloitte Consulting.\n",
      "\n",
      "I am excited about the opportunity to bring my unique blend of skills and experience to Barclays and am confident in my ability to provide high-quality data solutions for your team. Thank you for considering my application. I look forward to the possibility of discussing this exciting opportunity with you.\n",
      "\n",
      "Sincerely,\n",
      "Ganesh Raj K\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"write me a cover letter using this profile for the role of Data Scientist at Barclays\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkedinbot_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

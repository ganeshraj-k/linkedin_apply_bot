{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce GTX 1650\n",
      "I am excited about the opportunity to work at Microsoft because of the company's reputation for innovation and cutting-edge technology. With my background in data science, computer science, and experience as a Data Analyst and Data Engineer, I believe I can contribute effectively to Microsoft's mission of empowering individuals and organizations to achieve more through technology.\n",
      "\n",
      "My experience in utilizing data to drive insights and make informed decisions aligns well with Microsoft's focus on leveraging data to create impactful solutions. I am particularly interested in the opportunity to work with cloud computing technologies like Azure, given my experience with AWS and Azure.\n",
      "\n",
      "I am confident that my skills and experience make me a strong fit for a role at Microsoft, and I am eager to contribute to the company's success.\n",
      "\n",
      "Thank you for considering my application.\n",
      "\n",
      "Sincerely,\n",
      "Ganesh Raj Kyatham\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "from llama_index.core import Settings, VectorStoreIndex, SummaryIndex, SimpleDirectoryReader, PromptTemplate\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# Paths\n",
    "secrets_path = r\"C:\\Users\\localadmin\\Desktop\\new desktop\\linkedinsucks\\user_files\\secrets.json\"\n",
    "docs_path = r\"C:\\Users\\localadmin\\Desktop\\new desktop\\linkedinsucks\\linkedin_easyapply_bot\\all_data\\docs\"\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the name of the GPU\n",
    "    gpu_name = torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "    print(f\"Using GPU: {gpu_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Load secrets\n",
    "with open(secrets_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "OPENAI_API_KEY = data[\"OPENAI_KEY\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "system_prompt_gpt4 = \"\"\"\n",
    "answer questions from a job applicant's perspective\n",
    "\"\"\"\n",
    "# Initialize necessary language models\n",
    "gpt3_5_llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "gpt3_5_embed = OpenAIEmbedding(model=\"text-embedding-ada-002\", system_prompt = system_prompt_gpt4)\n",
    "# System prompt for the LLM\n",
    "\n",
    "\n",
    "\n",
    "# Load documents\n",
    "documents = SimpleDirectoryReader(docs_path).load_data()\n",
    "\n",
    "\n",
    "# Configure LLM settings\n",
    "Settings.llm = gpt3_5_llm\n",
    "Settings.embed_model = gpt3_5_embed\n",
    "\n",
    "# Create an index from documents\n",
    "summary_index = VectorStoreIndex(documents)\n",
    "\n",
    "# Create a query engine\n",
    "query_engine_summary = summary_index.as_query_engine(response_mode=\"refine\")\n",
    "\n",
    "# Define the prompt template\n",
    "qa_prompt_tmpl_str_gpt4 = \"\"\"\\\n",
    "Context information is below.\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge,\n",
    "it is very important that you follow the instructions clearly and answer based on the given information.\n",
    "Answer the query in the format requested in the query.\n",
    "Do not leave blanks in the answers.\n",
    "Always answer the questions in the form of a cover letter and in first person.\n",
    "If asked for a cover letter, write a short cover letter talking about your previous work experience and how it would make you a good fit for the given role.\n",
    "If asked about why you want to work at a certain company, write a concise cover letter including the company's name and talking about your previous work experience and how it would make you a good fit for the given role.\n",
    "\n",
    "Query: {query_str}\n",
    "Answer: \\\n",
    "\"\"\"\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str_gpt4)\n",
    "\n",
    "# Update query engine prompts\n",
    "query_engine_summary.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")\n",
    "\n",
    "# Example query\n",
    "response = query_engine_summary.query(\"why do you want to work at Microsoft\")\n",
    "print(response.response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkedinbot_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
